1.先运行 process_data.py，构造出特征，得到feature.csv
2.运行 fill_correlation.py 补充后面60天的皮尔逊相关系数，得到feature2.csv，这个运行比较久，在我的电脑上大概运行11个小时，这东西有两个用途，第一：前面算出来的20天皮尔逊系数能够加入训练集，因为仅用40天收益率序列算出来的皮尔逊系数还是比较准的；第二：最后用15天收益率序列算出来的皮尔逊系数，可以用来跟模型的结果进行融合。
3.然后运行conv_predict.py，运行结果在CheckPoint，会保存多个模型，选择val_score为0.85左右的，0.87以上的很大可能是过拟合了的；模型不稳定，训练5到10个模型求均值，分数比较高。
4.在CheckPoint中，如果出现val_score大于0.87的结果，很大可能是过拟合了，要重新选择一个val_score在0.85-0.86之间的，把名字写到load_model.py中，运行load_model.py重新生成结果。
5.运行merge_result.py，将多各conv模型的结果求均值，再将均值结果以7:3（初赛时3:7，复赛是2:8）的比例与最后一天的相关性值合并。还可以将得到的结果再与15天收益率序列算出来的皮尔逊系数融合，初赛能提高0.09，复赛好像不行了，跟conv的随机结果有关。